{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:05:03.828872Z",
     "start_time": "2019-12-16T13:05:00.766400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:05:04.427414Z",
     "start_time": "2019-12-16T13:05:03.830738Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/w_review_train.csv',header=None)\n",
    "train.columns = ['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:05:04.451925Z",
     "start_time": "2019-12-16T13:05:04.430162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>ในวันที่เร่งรีบ ไม่รู้จะกินอะไรมองหาร้านที่คนน...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>รอรถไฟกลับนครปฐมค่ะ ฝนตกพรำๆตลอดที่มาที่นี่ พอ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>คราวนี้ได้มีโอกาสมาลองร้านไอติมเปิดใหม่ที่ส่งม...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8198</th>\n",
       "      <td>ร้านนี้โดดเด่นด้วยป้ายบอกร้านที่สูงลิบลิ่ว และ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31403</th>\n",
       "      <td>ร้านนี้อยู่ตรงหน้า 7-11 ที่เป็นแหล่งรวมรถเข็นข...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13917</th>\n",
       "      <td>เป็นร้านที่มีบรรยากาศค่อนข้างสวย  ตบแต่งมีสไตล...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27440</th>\n",
       "      <td>สเต็กโชกุนอยู่ริมถนนเพชรเกษม เกือบถึงซอยวัดม่ว...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11667</th>\n",
       "      <td>ชอบลูกชิ้นปลาร้านนี้ สั่งเย็นตาโฟมากิน รสชาติเ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29616</th>\n",
       "      <td>ร้านเย็นตาโฟในตำนานของ ม.นเรศวร\\nรอบนี้มาลองสั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39864</th>\n",
       "      <td>เวลามีเพื่อน หรือญาติผู้ใหญ่แวะมาเยี่ยมเยียน เ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "12836  ในวันที่เร่งรีบ ไม่รู้จะกินอะไรมองหาร้านที่คนน...\n",
       "10913  รอรถไฟกลับนครปฐมค่ะ ฝนตกพรำๆตลอดที่มาที่นี่ พอ...\n",
       "4214   คราวนี้ได้มีโอกาสมาลองร้านไอติมเปิดใหม่ที่ส่งม...\n",
       "8198   ร้านนี้โดดเด่นด้วยป้ายบอกร้านที่สูงลิบลิ่ว และ...\n",
       "31403  ร้านนี้อยู่ตรงหน้า 7-11 ที่เป็นแหล่งรวมรถเข็นข...\n",
       "13917  เป็นร้านที่มีบรรยากาศค่อนข้างสวย  ตบแต่งมีสไตล...\n",
       "27440  สเต็กโชกุนอยู่ริมถนนเพชรเกษม เกือบถึงซอยวัดม่ว...\n",
       "11667  ชอบลูกชิ้นปลาร้านนี้ สั่งเย็นตาโฟมากิน รสชาติเ...\n",
       "29616  ร้านเย็นตาโฟในตำนานของ ม.นเรศวร\\nรอบนี้มาลองสั...\n",
       "39864  เวลามีเพื่อน หรือญาติผู้ใหญ่แวะมาเยี่ยมเยียน เ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:05:04.460902Z",
     "start_time": "2019-12-16T13:05:04.455453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:05:04.471872Z",
     "start_time": "2019-12-16T13:05:04.461937Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-8060b2774adc>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-8060b2774adc>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    print(f\"{ind} : {train.iloc[ind].values[0]} \\n\")\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "rand_ind = np.random.randint(low = 0, high = train.shape[0], size = 5)\n",
    "\n",
    "for ind in rand_ind:\n",
    "    print(f\"{ind} : {train.iloc[ind].values[0]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:05:05.504650Z",
     "start_time": "2019-12-16T13:05:04.473867Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:09:38.606880Z",
     "start_time": "2019-12-16T13:09:38.602890Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REDUCE SIZE TRAIN\n",
    "train = train.head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:25:06.054033Z",
     "start_time": "2019-12-16T13:24:41.978393Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['word_tokenized'] = train['review'].apply(lambda x: word_tokenize(x,engine='attacut',keep_whitespace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:07:00.308899Z",
     "start_time": "2019-12-16T14:07:00.271954Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:25:06.085948Z",
     "start_time": "2019-12-16T13:25:06.079964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['len_review'] = train['word_tokenized'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:25:06.120243Z",
     "start_time": "2019-12-16T13:25:06.087942Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['word_tokenized_uniq'] = train['word_tokenized'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:25:06.128872Z",
     "start_time": "2019-12-16T13:25:06.121851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['len_review_uniq'] = train['word_tokenized_uniq'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:04:22.714660Z",
     "start_time": "2019-12-16T14:04:22.712631Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "special_char = '''\n",
    "~:\"\"+[\\\\@^%(-\"*|&<`._=]!>;?#$)/,ๆ'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:52:33.422243Z",
     "start_time": "2019-12-16T13:52:33.399264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['word_tokenized_uniq_cls'] = train['word_tokenized_uniq'].apply(lambda x : [w for w in x if w not in special_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:52:33.658994Z",
     "start_time": "2019-12-16T13:52:33.652012Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['len_review_uniq_cls'] = train['word_tokenized_uniq_cls'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thai_stopword_ls = list(pythainlp.corpus.thai_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:54:06.312958Z",
     "start_time": "2019-12-16T13:54:05.447808Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['word_tokenized_uniq_cls_revstopw'] = train['word_tokenized_uniq_cls'].apply(lambda x : [w for w in x if w not in thai_stopword_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:54:06.643272Z",
     "start_time": "2019-12-16T13:54:06.639280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['len_review_uniq_cls_revstopw'] = train['word_tokenized_uniq_cls_revstopw'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:54:07.090189Z",
     "start_time": "2019-12-16T13:54:07.068256Z"
    }
   },
   "outputs": [],
   "source": [
    "train[['len_review','len_review_uniq','len_review_uniq_cls','len_review_uniq_cls_revstopw']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:54:17.242541Z",
     "start_time": "2019-12-16T13:54:17.235559Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.loc[train['len_review_uniq_cls_revstopw'] == 16]['review'].values)\n",
    "print('\\n')\n",
    "print(train.loc[train['len_review_uniq_cls_revstopw'] == 16]['word_tokenized_uniq_cls_revstopw'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:57:28.102152Z",
     "start_time": "2019-12-16T14:57:28.084223Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train.loc[train['len_review_uniq_cls_revstopw'] == 303]['review'].values)\n",
    "print('\\n')\n",
    "print(train.loc[train['len_review_uniq_cls_revstopw'] == 303]['word_tokenized_uniq_cls_revstopw'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:00:26.917369Z",
     "start_time": "2019-12-16T14:00:26.877444Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "ind = 16\n",
    "print(train.iloc[ind]['word_tokenized'])\n",
    "print('\\n')\n",
    "print(train.iloc[ind]['word_tokenized_uniq'])\n",
    "print('\\n')\n",
    "print([word for word in train.iloc[ind]['word_tokenized_uniq'] if word not in special_char and word not in thai_stopword_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:41:01.440373Z",
     "start_time": "2019-12-16T13:40:32.299489Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "ind = 20\n",
    "print(train.iloc[ind]['word_tokenized'])\n",
    "print('\\n')\n",
    "print(train.iloc[ind]['word_tokenized_uniq'])\n",
    "print('\\n')\n",
    "print([word for word in train.iloc[ind]['word_tokenized_uniq'] if word not in special_char])\n",
    "print('\\n')\n",
    "print([correct(word) for word in train.iloc[ind]['word_tokenized_uniq'] if word not in special_char])\n",
    "# special characther will be replace by \"ใน\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag or word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:10:33.282973Z",
     "start_time": "2019-12-16T14:10:31.202687Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:11:21.198601Z",
     "start_time": "2019-12-16T14:11:21.168978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_docs = train['word_tokenized_uniq_cls_revstopw'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:11:22.304925Z",
     "start_time": "2019-12-16T14:11:22.200206Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:13:33.137331Z",
     "start_time": "2019-12-16T14:13:33.114382Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:13:42.680594Z",
     "start_time": "2019-12-16T14:13:42.674624Z"
    }
   },
   "outputs": [],
   "source": [
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:14:02.755167Z",
     "start_time": "2019-12-16T14:14:02.705901Z"
    }
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:16:18.251720Z",
     "start_time": "2019-12-16T14:16:18.246733Z"
    }
   },
   "outputs": [],
   "source": [
    "bow_doc_4310 = bow_corpus[500]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:21:48.297949Z",
     "start_time": "2019-12-16T14:21:48.278965Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:30:08.809401Z",
     "start_time": "2019-12-16T14:30:05.437040Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:30:08.818340Z",
     "start_time": "2019-12-16T14:30:08.811399Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('\\n')\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:55:32.329968Z",
     "start_time": "2019-12-16T14:55:15.028144Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf,\n",
    "                                             num_topics=30, id2word=dictionary, passes=20, workers=4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:55:32.340903Z",
     "start_time": "2019-12-16T14:55:32.330930Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('\\n')\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T14:57:28.102152Z",
     "start_time": "2019-12-16T14:57:28.084223Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in range(0,500,75):\n",
    "    print(\"*\"*30,ind,\"*\"*30)\n",
    "    print([train['review'][ind]])\n",
    "    for index, score in sorted(lda_model_tfidf[bow_corpus[ind]], key=lambda tup: -1*tup[1]):\n",
    "        print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T13:07:34.549744Z",
     "start_time": "2019-12-16T13:07:34.544775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FULL LOOP\n",
    "# chunk_ind = list(range(0,train.shape[0],4000))\n",
    "# chunk_ind\n",
    "\n",
    "# import tqdm\n",
    "\n",
    "# for ind in tqdm.tqdm(chunk_ind):\n",
    "#     train_ = train.iloc[chunk_ind[ind]:chunk_ind[ind+1]].copy()\n",
    "#     train_ = train_['review'].apply(lambda x: word_tokenize(x,engine='deepcut'))\n",
    "#     train_.to_csv(f'../data/interim/train_tokenized_deepcut_chnk{ind}.csv', index=False)\n",
    "#     del train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
